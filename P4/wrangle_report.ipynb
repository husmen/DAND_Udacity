{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle and Analyze Data\n",
    "#### Wrangling report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather\n",
    "Due to some issues with the Twitter developer account, I decided to take the shortcut approach instead since it is allowed. On the plus side, it saves time and allows for a cleaner notebook.\n",
    "\n",
    "The data comes from 3 different source:\n",
    "\n",
    "* Enhanced Twitter Archive: WeRateDogs Twitter archive, accessible as a local csv file.\n",
    "\n",
    "* Image Predictions File: results of an image classifier for dog breeds, accessible as an online tsv file.\n",
    "\n",
    "* Additional Data: accessible via Twitter API (or alternatively local json file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess\n",
    "\n",
    "**The Process**\n",
    "\n",
    "This has been achieved through a series operations on each of the datasets, this includes:\n",
    "\n",
    "* visually checking samples of the data\n",
    "\n",
    "* calculating and investigating some key stats\n",
    "\n",
    "* checking for nulls\n",
    "\n",
    "* checking for duplicates\n",
    "\n",
    "**Observations on quality**\n",
    "\n",
    "* Incorrect dog names including None and a\n",
    "\n",
    "* `timestamp` is `object`, should be `datetime`\n",
    "\n",
    "* `tweet_id` is `int`, should be `str` \n",
    "\n",
    "* Some columns have missing data\n",
    "\n",
    "* `id` should be renamed `tweet_id` for consistency\n",
    "\n",
    "* many dogs aren't classified (dogger, pupper ...)\n",
    "\n",
    "* unusual rating scale, making comparisons difficult\n",
    "\n",
    "* tables don't have the same number of entries, meaning there are missing lines\n",
    "\n",
    "* several denominator values, including 0!\n",
    "\n",
    "* different number of retweets depending on how to filter for it\n",
    "\n",
    "* only predictions with highest pobability are neede\n",
    "\n",
    "* retweets and replies included but not needed\n",
    "\n",
    "**Observations on tidiness**\n",
    "\n",
    "* last 4 columns can be replaced with one\n",
    "\n",
    "* this data can be combined in 1 table instead of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "\n",
    "**I followed these steps**\n",
    "\n",
    "* change `id` and `tweet_id` types to `str`\n",
    "\n",
    "* rename `id` to `tweet_id` and cast as string\n",
    "\n",
    "* join all tables on `tweet_id`\n",
    "\n",
    "* parse ratings from text accurately\n",
    "\n",
    "* calculate a rating score\n",
    "\n",
    "* replace wrong dog names with `None`\n",
    "\n",
    "* remove retweets and related columns\n",
    "\n",
    "* change `timestamp` type to `datetime` \n",
    "\n",
    "* combine `[\"doggo\", \"floofer\", \"pupper\", \"puppo\"]` columns into one as `stage`, renaming multiple stages to [chimera](https://i.imgur.com/WeeuxcC.png).\n",
    "\n",
    "* remove low confidence predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project provides us with the opportunity to to practice the whole data wrangling process from start to finish.\n",
    "\n",
    "I started by gathering the data from the 3 different sources and checking several aspects of it to get an idea on what issues are there, in terms of both quality and tidiness.\n",
    "\n",
    "In the second step, I worked on addressing those issues as best as I can, and ended up with a much cleaner dataset that I saved locally. Some issues have not been addressed though, like the accuracy of rating values, and the messy source column.\n",
    "\n",
    "Finally, It was time for getting some insights from the final dataset. Its details are discussed in `act_report.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call([\"python\", \"-m\", \"nbconvert\", \"wrangle_report.ipynb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
